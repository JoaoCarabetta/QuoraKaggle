{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "import logging\n",
    "import string\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/thiagocunha/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "quora_train = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   id  qid1  qid2                                          question1  \\\n",
      "0   0     1     2  What is the step by step guide to invest in sh...   \n",
      "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
      "2   2     5     6  How can I increase the speed of my internet co...   \n",
      "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
      "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
      "\n",
      "                                           question2  is_duplicate  \n",
      "0  What is the step by step guide to invest in sh...             0  \n",
      "1  What would happen if the Indian government sto...             0  \n",
      "2  How can Internet speed be increased by hacking...             0  \n",
      "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
      "4            Which fish would survive in salt water?             0  \n"
     ]
    }
   ],
   "source": [
    "print (type(quora_train))\n",
    "print(quora_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404288"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(quora_train['is_duplicate'] == quora_train['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404288"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(quora_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Editing questions with NLTK package\n",
    "\n",
    "def remove_stopwords(phrase,list_stopwords):\n",
    "    \"\"\"\n",
    "    Receives a phrase and removes all stopwords from a list\n",
    "    :param phrase: String. A phrase.\n",
    "    :param list_stopwords: List. A list of stopwords\n",
    "    :return: The same phrase without stopwords\n",
    "    \"\"\"\n",
    "    final_phrase = []\n",
    "    words = phrase.split(\" \")\n",
    "    for word in words:\n",
    "        if word not in list_stopwords:\n",
    "            final_phrase.append((word))\n",
    "    \n",
    "    final_phrase = ' '.join(final_phrase)\n",
    "    \n",
    "    return final_phrase\n",
    "    \n",
    "def remove_punctuation(phrase):\n",
    "    \"\"\"\n",
    "    Receives a phrase and removes all punctuation from it\n",
    "    :param phrase: String. A phrase.\n",
    "    :return: The same phrase without punctuation\n",
    "    \"\"\"\n",
    "    #Check if NA\n",
    "    if type(phrase) is float:\n",
    "        if math.isnan(phrase):\n",
    "            return (\"\")\n",
    "    \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    phrase = phrase.translate(translator) #removing punctuation\n",
    "        \n",
    "    return phrase\n",
    "\n",
    "def lemm_wordnet(phrase):\n",
    "    \"\"\"\n",
    "    Receives a phrase and removes lemmatizes it\n",
    "    :param phrase: String. A phrase.\n",
    "    :return: The same phrase in lemmas\n",
    "    \"\"\"\n",
    "    lemm = WordNetLemmatizer()\n",
    "    \n",
    "    #NA is a float type, so this if is to avoid conflict\n",
    "    if type(phrase) is not float:\n",
    "        phrase = [lemm.lemmatize(i) for i in phrase.split()]\n",
    "        phrase = ' '.join(phrase)\n",
    "    else:\n",
    "        return \"\"\n",
    "    return phrase\n",
    "    \n",
    "def remove_duplicate(phrase):\n",
    "    \"\"\"\n",
    "    Receives a phrase and removes all duplicate words\n",
    "    :param phrase: String. A phrase.\n",
    "    :return: The same phrase with just unique words\n",
    "    \"\"\"\n",
    "    aux_phrase = []\n",
    "        \n",
    "    if type(phrase) is not float:\n",
    "        \n",
    "        for i in phrase.split():\n",
    "            \n",
    "            if i not in aux_phrase:\n",
    "                aux_phrase.append(i)\n",
    "    \n",
    "    phrase = ' '.join(aux_phrase)\n",
    "    \n",
    "    return phrase\n",
    "    \n",
    "    \n",
    "def all_lower_case(phrase):    \n",
    "    \"\"\"\n",
    "    Receives a phrase and makes it lower case\n",
    "    :param phrase: String. A phrase.\n",
    "    :return: The same phrase in lower case\n",
    "    \"\"\"\n",
    "    if type(phrase) is not float:\n",
    "            phrase = phrase.lower()\n",
    "    return phrase\n",
    "    \n",
    "def stem_snowball(phrase):\n",
    "    \"\"\"\n",
    "    Receives a phrase and returns the same phrase stemmed, lowercase phrase without stopwords\n",
    "    :param phrase: String. A phrase.\n",
    "    :return: String. Stemmed, lowercase phrase without stopwords\n",
    "    \"\"\"\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    #Stem words according to stemmer\n",
    "    final_phrase = []\n",
    "    words = phrase.split(\" \")\n",
    "    for word in words:\n",
    "        final_phrase.append((stemmer.stem(word)))\n",
    "    \n",
    "    final_phrase = ' '.join(final_phrase)\n",
    "    \n",
    "    return final_phrase\n",
    "\n",
    "stem_snowball(\"What is the step by step guide to invest in share market in india?\")\n",
    "\n",
    "#This function will return a Bag of words of our two questions using TF method\n",
    "def vectorizer_tf(data, features = 5000):\n",
    "    \"\"\"\n",
    "    Receives the data frame. Merges all words in question1 and question2 and vectorizes with tf algorithm.\n",
    "    :param phrase: data frame.\n",
    "    :param features: number of features for the vectorizes.\n",
    "    :return: An array with #number of features\n",
    "    \"\"\"\n",
    "    vectorizer_count = CountVectorizer(ngram_range=(1, 2), max_features = features)\n",
    "    \n",
    "    merge = data.question1.append([data.question2])\n",
    "    \n",
    "    vector_fitt = vectorizer_count.fit(merge)\n",
    "    \n",
    "    question1 = vector_fitt.transform(data.question1)\n",
    "    question2 = vector_fitt.transform(data.question2)\n",
    "    \n",
    "    question1 = question1.toarray()\n",
    "    question2 = question2.toarray()\n",
    "    \n",
    "    return question1 + question2\n",
    "\n",
    "#This function will return a Bag of words of our two questions using TF-idf method\n",
    "\n",
    "def vectorizer_tf_idf(data, features = 5000):\n",
    "    \"\"\"\n",
    "    Receives the data frame. Merges all words in question1 and question2 and vectorizes with tf-idf algorithm.\n",
    "    :param data: data frame.\n",
    "    :param features: number of features for the vectorizes.\n",
    "    :return: An array with #number of features\n",
    "    \"\"\"\n",
    "    vectorizer_tf_idf = TfidfVectorizer(ngram_range=(1, 2), max_features = features, sublinear_tf=True)\n",
    "    \n",
    "    merge = data.question1.append([data.question2])\n",
    "    \n",
    "    vector_tf_idf_fitt = vectorizer_tf_idf.fit(merge)\n",
    "    \n",
    "    question1 = vector_tf_idf_fitt.transform(data.question1)\n",
    "    question2 = vector_tf_idf_fitt.transform(data.question2)\n",
    "        \n",
    "    question1 = question1.toarray()\n",
    "    question2 = question2.toarray()\n",
    "    \n",
    "    return question1 + question2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cleaning tool is used so you can easily choose which functions you want to use to clean te text\n",
    "def cleaning_tool(data, drop_na = True, lower_case = True, rm_duplicate = False, stopwords = False, \n",
    "                  punctuation = False, lemm = False, stem = False, list_of_stopwords = None):\n",
    "    \"\"\"\n",
    "    Function to process all data using calling functions from above, according to what was chosen.\n",
    "    :param data: data frame.\n",
    "    :param drop_na: If True drop all lines of data frame with NA\n",
    "    :param lower_case: If True transform for lower case\n",
    "    :param rm_duplicate: If True remove all duplicate words in questions\n",
    "    :param stopwords: If True removes stopwords\n",
    "    :param punctuation: If True removes punctuation\n",
    "    :param lemm: If True returns the phrase lemmatized\n",
    "    :param stem: If True returns the phrase stemmed\n",
    "    :param list_of_stopwords: List of stopwords to be used\n",
    "    :return: Question1 and Question2 processed according to parameters\n",
    "    \"\"\"\n",
    "    if drop_na == True:\n",
    "        data = data.dropna(0)\n",
    "    \n",
    "    if rm_duplicate == True:\n",
    "        data[\"question1\"] = data[\"question1\"].apply(lambda x: remove_duplicate(x))\n",
    "        data[\"question2\"] = data[\"question2\"].apply(lambda x: remove_duplicate(x))\n",
    "    \n",
    "    if lower_case == True:\n",
    "        data[\"question1\"] = data[\"question1\"].apply(lambda x: all_lower_case(x))\n",
    "        data[\"question2\"] = data[\"question2\"].apply(lambda x: all_lower_case(x))\n",
    "    \n",
    "    if stopwords == True:\n",
    "        data[\"question1\"] = data[\"question1\"].apply(lambda x: remove_stopwords(x, list_of_stopwords))\n",
    "        data[\"question2\"] = data[\"question2\"].apply(lambda x: remove_stopwords(x, list_of_stopwords))\n",
    "       \n",
    "    if punctuation == True:\n",
    "        data[\"question1\"] = data[\"question1\"].apply(lambda x: remove_punctuation(x))\n",
    "        data[\"question2\"] = data[\"question2\"].apply(lambda x: remove_punctuation(x))\n",
    "        \n",
    "    if lemm_wordnet == True:\n",
    "        data[\"question1\"] = data[\"question1\"].apply(lambda x: lemm_wordnet(x))\n",
    "        data[\"question2\"] = data[\"question2\"].apply(lambda x: lemm_wordnet(x))\n",
    "        \n",
    "    if stem_snowball == True:\n",
    "        data[\"question1\"] = data[\"question1\"].apply(lambda x: stem_snowball(x))\n",
    "        data[\"question2\"] = data[\"question2\"].apply(lambda x: stem_snowball(x))\n",
    "    \n",
    "    #We used it two times if some function create a new NA.\n",
    "    if drop_na == True:\n",
    "        data = data.dropna(0)    \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Quora Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "quora_train = cleaning_tool(quora_train, lemm = True, rm_duplicate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#quora_train = quora_train.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "    \n",
    "quora_train_tf = vectorizer_tf(quora_train, features = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quora_train_tf_idf = vectorizer_tf_idf(quora_train, features = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store edited databases w/ Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileObject = open(\"Edited_Base_stem_stopwords\",'wb') \n",
    "pickle.dump(quora_train,fileObject)  \n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileObject = open(\"Edited_Base_stem_stopwords\",'rb')  \n",
    "quora_train = pickle.load(fileObject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The function train_test_split transform your databse in 4 parts, \n",
    "the first one is the new \"train\" database without the independent variable, \n",
    "the second one is the new test database without the independent variable,\n",
    "the third one is just the independent variable from the first part and\n",
    "the fourht one is just the independent variable from the second part.\n",
    "'''\n",
    "\n",
    "quora_train_features_tf, quora_test_features_tf, quora_train_y_tf, quora_test_y_tf = model_selection.train_test_split(\n",
    "    quora_train_tf, quora_train['is_duplicate'], test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quora_train_features_tf_idf, quora_test_features_tf_idf, quora_train_y_tf_idf, quora_test_y_tf_idf = model_selection.train_test_split(\n",
    "    quora_train_tf_idf, quora_train['is_duplicate'], test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_common_percentage(df):\n",
    "    \"\"\"\n",
    "    Receives the initial data frame and adds  the colunms \"num_words_common\", \"num_words_total\" and \"common_percentage\"\n",
    "    :param package_name: Data frame train.csv from the Kaggle website\n",
    "    :return: Data frame with added colunms \"num_words_common\", \"num_words_total\" and \"common_percentage\"\n",
    "    \"\"\"\n",
    "    num_words_common = []\n",
    "    num_words_total = []\n",
    "\n",
    "    for line in range(0,len(df)):\n",
    "        count_total = 0\n",
    "        count_common = 0\n",
    "        for word in df[\"question1_edited\"][line].split(\" \"):\n",
    "            if word in df[\"question2_edited\"][line]:\n",
    "                count_common = count_common+1\n",
    "            count_total = count_total+1\n",
    "        num_words_common.append(count_common) \n",
    "        num_words_total.append(count_total)\n",
    "\n",
    "    num_words_common = pd.Series(num_words_common)\n",
    "    num_words_total = pd.Series(num_words_total)\n",
    "\n",
    "    df[\"num_words_common\"] = num_words_common.values\n",
    "    df[\"num_words_total\"] = num_words_total.values\n",
    "    df[\"common_percentage\"] = df[\"num_words_common\"]/df[\"num_words_total\"]\n",
    "\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quora_train = calculate_common_percentage(quora_train)\n",
    "#\"num_words_common\", \"num_words_total\" and \"common_percentage\"\n",
    "plt.figure()\n",
    "#plt.boxplot(quora_train[\"common_percentage\"],quora_train[\"is_duplicate\"])\n",
    "\n",
    "\n",
    "quora_train.boxplot(column='common_percentage', by='is_duplicate')\n",
    "plt.suptitle('')\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-0.2,1.1])\n",
    "plt.title(\"Common word percentage and is_duplicate\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest_tf = RandomForestClassifier(n_estimators=300, max_features='auto', bootstrap=False, \n",
    "                               oob_score=False, n_jobs=-1, random_state=0).fit(quora_train_features_tf, quora_train_y_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomforest_tf_score = randomforest_tf.score(quora_test_features_tf, quora_test_y_tf)\n",
    "print(randomforest_tf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_tf = randomforest_tf.predict_proba(quora_test_features_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss(quora_test_y_tf,predict_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomforest_tf_idf = RandomForestClassifier(n_estimators=300, max_features='auto', bootstrap=False, \n",
    "                               oob_score=False, n_jobs=-1, random_state=0).fit(quora_train_features_tf_idf, quora_train_y_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomforest_tf_score_idf = randomforest_tf_idf.score(quora_test_features_tf_idf, quora_test_y_tf_idf)\n",
    "print(randomforest_tf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_tf_idf = randomforest_tf_idf.predict_proba(quora_test_features_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss(quora_test_y_tf,predict_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "clf_LR_tf = LR(penalty='l2',\n",
    "               dual=False,\n",
    "               tol=0.0001,\n",
    "               C=1.0,\n",
    "               fit_intercept=True,\n",
    "               intercept_scaling=1,\n",
    "               class_weight=None,\n",
    "               random_state=0,\n",
    "               solver='liblinear',\n",
    "               max_iter=100,\n",
    "               multi_class='ovr',\n",
    "               verbose=0).fit(quora_train_features_tf, quora_train_y_tf)\n",
    "\n",
    "eval_LR_tf_tts = clf_LR_tf.score(quora_test_features_tf, quora_test_y_tf)\n",
    "print(eval_LR_tf_tts)\n",
    "predict_tf = clf_LR_tf.predict_proba(quora_test_features_tf)\n",
    "log_loss(quora_test_y_tf,predict_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_LR_tfidf = LR(penalty='l2',\n",
    "                  dual=False,\n",
    "                  tol=0.0001,\n",
    "                  C=1.0,\n",
    "                  fit_intercept=True,\n",
    "                  intercept_scaling=1,\n",
    "                  class_weight=None,\n",
    "                  random_state=0,\n",
    "                  solver='liblinear',\n",
    "                  max_iter=100,\n",
    "                  multi_class='ovr',\n",
    "                  verbose=0).fit(quora_train_features_tf_idf, quora_train_y_tf_idf)\n",
    "\n",
    "eval_LR_tf_idf_tts = clf_LR_tfidf.score(quora_test_features_tf_idf, quora_test_y_tf_idf)\n",
    "print(eval_LR_tf_idf_tts)\n",
    "predict_tf_idf = clf_LR_tf.predict_proba(quora_test_features_tf_idf)\n",
    "log_loss(quora_test_y_tf_idf,predict_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "accuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: Random-Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set external parameters\n",
    "    model_name = 'Random-Forest'\n",
    "    k = 10\n",
    "    data = quora_train\n",
    "    output_name = 'is_duplicate'\n",
    "    \n",
    "#reset internal parameters\n",
    "    n = len(data)\n",
    "    total_accuracy = 0\n",
    "    \n",
    "#i-fold validation\n",
    "    for i in range(0, k):\n",
    "        start = (n*i)/k\n",
    "        end = (n*(i+1))/k-1\n",
    "        \n",
    "    #split training anda validation set\n",
    "        validation_set = data[start:end+1]\n",
    "        \n",
    "        if i == 0:\n",
    "            training_set = data[end+1:n+1]\n",
    "            \n",
    "        elif i == k-1:\n",
    "            training_set = data[0:start]\n",
    "        else:\n",
    "            training_set_part1 = data[0:start]\n",
    "            training_set_part2 = data[end+1:n+1]\n",
    "            training_set = training_set_part1.append(training_set_part2)\n",
    "        \n",
    "        \n",
    "    #model training\n",
    "        trained_model = #graphlab.linear_regression.create(training_set, target = output_name, features = features_list,\n",
    "                                                  #validation_set = None, l2_penalty = l2_penalty)\n",
    "        \n",
    "    #calculate accuracy of the model\n",
    "\n",
    "        predictions = #trained_model.predict(validation_set)\n",
    "\n",
    "        total_accuracy += sum(validation_set[output_name] == predictions)/len(validation_set)        \n",
    "\n",
    "    \n",
    "#record the result\n",
    "    models.append(model_name)\n",
    "    accuracy.append(total_accuracy/k)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAIkCAYAAAA+v7zpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124f375c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_series = pd.Series.from_array(accuracy) \n",
    "x_labels = models \n",
    "\n",
    "# now to plot the figure...\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = accuracy_series.plot(kind='bar')\n",
    "ax.set_title(\"Models Accuracy\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xticklabels(x_labels)\n",
    "\n",
    "rects = ax.patches\n",
    "\n",
    "# Now make some labels\n",
    "labels = accuracy\n",
    "\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 0.01 , label, ha='center', va='bottom')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
