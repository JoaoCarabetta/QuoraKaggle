{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as p\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOAD FEATURES\n",
    "\n",
    "Carrega o train set com a features e deleta possíveis nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('quora_train_engineered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404290\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>len_char_q2</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>...</th>\n",
       "      <th>cityblock_distance</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "      <th>skew_q1vec</th>\n",
       "      <th>skew_q2vec</th>\n",
       "      <th>kur_q1vec</th>\n",
       "      <th>kur_q2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>5.081614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.023324</td>\n",
       "      <td>0.371408</td>\n",
       "      <td>0.168999</td>\n",
       "      <td>0.186557</td>\n",
       "      <td>0.031817</td>\n",
       "      <td>-0.091902</td>\n",
       "      <td>0.050416</td>\n",
       "      <td>0.337301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  is_duplicate  len_q1  \\\n",
       "0  What is the step by step guide to invest in sh...             0      66   \n",
       "\n",
       "   len_q2  diff_len  len_char_q1  len_char_q2  len_word_q1  len_word_q2  \\\n",
       "0      57         9           20           20           14           12   \n",
       "\n",
       "     ...      cityblock_distance  jaccard_distance  canberra_distance  \\\n",
       "0    ...                5.081614               1.0          94.023324   \n",
       "\n",
       "   euclidean_distance  minkowski_distance  braycurtis_distance  skew_q1vec  \\\n",
       "0            0.371408            0.168999             0.186557    0.031817   \n",
       "\n",
       "   skew_q2vec  kur_q1vec  kur_q2vec  \n",
       "0   -0.091902   0.050416   0.337301  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_features))\n",
    "train_features.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402489\n"
     ]
    }
   ],
   "source": [
    "train_features = train_features.dropna()\n",
    "print(len(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393325\n"
     ]
    }
   ],
   "source": [
    "train_features = train_features.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "print(len(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>len_char_q2</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>common_words</th>\n",
       "      <th>fuzz_qratio</th>\n",
       "      <th>...</th>\n",
       "      <th>cityblock_distance</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "      <th>skew_q1vec</th>\n",
       "      <th>skew_q2vec</th>\n",
       "      <th>kur_q1vec</th>\n",
       "      <th>kur_q2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "      <td>393325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.373147</td>\n",
       "      <td>60.311986</td>\n",
       "      <td>60.915289</td>\n",
       "      <td>-0.603303</td>\n",
       "      <td>20.358383</td>\n",
       "      <td>20.346022</td>\n",
       "      <td>11.087015</td>\n",
       "      <td>11.333958</td>\n",
       "      <td>4.577741</td>\n",
       "      <td>58.347913</td>\n",
       "      <td>...</td>\n",
       "      <td>9.168629</td>\n",
       "      <td>0.931813</td>\n",
       "      <td>131.565848</td>\n",
       "      <td>0.662708</td>\n",
       "      <td>0.298953</td>\n",
       "      <td>0.367942</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.010401</td>\n",
       "      <td>-0.052685</td>\n",
       "      <td>-0.054127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.483641</td>\n",
       "      <td>29.816552</td>\n",
       "      <td>33.826257</td>\n",
       "      <td>32.729612</td>\n",
       "      <td>4.103479</td>\n",
       "      <td>4.232956</td>\n",
       "      <td>5.403554</td>\n",
       "      <td>6.298609</td>\n",
       "      <td>3.106880</td>\n",
       "      <td>21.973585</td>\n",
       "      <td>...</td>\n",
       "      <td>4.264971</td>\n",
       "      <td>0.252065</td>\n",
       "      <td>47.306981</td>\n",
       "      <td>0.308122</td>\n",
       "      <td>0.139067</td>\n",
       "      <td>0.195305</td>\n",
       "      <td>0.135298</td>\n",
       "      <td>0.134904</td>\n",
       "      <td>0.265730</td>\n",
       "      <td>0.264215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1080.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.669451</td>\n",
       "      <td>-0.669451</td>\n",
       "      <td>-0.857844</td>\n",
       "      <td>-0.829341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.601517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>112.802617</td>\n",
       "      <td>0.477007</td>\n",
       "      <td>0.215150</td>\n",
       "      <td>0.245304</td>\n",
       "      <td>-0.080458</td>\n",
       "      <td>-0.080101</td>\n",
       "      <td>-0.238232</td>\n",
       "      <td>-0.239380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.194268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>138.476616</td>\n",
       "      <td>0.664615</td>\n",
       "      <td>0.299724</td>\n",
       "      <td>0.351586</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.011953</td>\n",
       "      <td>-0.081463</td>\n",
       "      <td>-0.082807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.827348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>160.990508</td>\n",
       "      <td>0.854588</td>\n",
       "      <td>0.385468</td>\n",
       "      <td>0.471933</td>\n",
       "      <td>0.101535</td>\n",
       "      <td>0.100640</td>\n",
       "      <td>0.101924</td>\n",
       "      <td>0.100228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>1169.000000</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.511668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>230.190867</td>\n",
       "      <td>1.496936</td>\n",
       "      <td>0.682163</td>\n",
       "      <td>1.101037</td>\n",
       "      <td>0.675833</td>\n",
       "      <td>0.781670</td>\n",
       "      <td>2.288984</td>\n",
       "      <td>2.227666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate         len_q1         len_q2       diff_len  \\\n",
       "count  393325.000000  393325.000000  393325.000000  393325.000000   \n",
       "mean        0.373147      60.311986      60.915289      -0.603303   \n",
       "std         0.483641      29.816552      33.826257      32.729612   \n",
       "min         0.000000       1.000000       2.000000   -1080.000000   \n",
       "25%         0.000000      40.000000      40.000000     -12.000000   \n",
       "50%         0.000000      52.000000      51.000000       0.000000   \n",
       "75%         1.000000      72.000000      72.000000      12.000000   \n",
       "max         1.000000     623.000000    1169.000000     487.000000   \n",
       "\n",
       "         len_char_q1    len_char_q2    len_word_q1    len_word_q2  \\\n",
       "count  393325.000000  393325.000000  393325.000000  393325.000000   \n",
       "mean       20.358383      20.346022      11.087015      11.333958   \n",
       "std         4.103479       4.232956       5.403554       6.298609   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%        18.000000      17.000000       8.000000       7.000000   \n",
       "50%        20.000000      20.000000      10.000000      10.000000   \n",
       "75%        23.000000      23.000000      13.000000      13.000000   \n",
       "max        52.000000      55.000000     125.000000     237.000000   \n",
       "\n",
       "        common_words    fuzz_qratio      ...        cityblock_distance  \\\n",
       "count  393325.000000  393325.000000      ...             393325.000000   \n",
       "mean        4.577741      58.347913      ...                  9.168629   \n",
       "std         3.106880      21.973585      ...                  4.264971   \n",
       "min         0.000000       0.000000      ...                  0.000000   \n",
       "25%         2.000000      41.000000      ...                  6.601517   \n",
       "50%         4.000000      59.000000      ...                  9.194268   \n",
       "75%         6.000000      76.000000      ...                 11.827348   \n",
       "max        41.000000     100.000000      ...                 20.511668   \n",
       "\n",
       "       jaccard_distance  canberra_distance  euclidean_distance  \\\n",
       "count     393325.000000      393325.000000       393325.000000   \n",
       "mean           0.931813         131.565848            0.662708   \n",
       "std            0.252065          47.306981            0.308122   \n",
       "min            0.000000           0.000000            0.000000   \n",
       "25%            1.000000         112.802617            0.477007   \n",
       "50%            1.000000         138.476616            0.664615   \n",
       "75%            1.000000         160.990508            0.854588   \n",
       "max            1.000000         230.190867            1.496936   \n",
       "\n",
       "       minkowski_distance  braycurtis_distance     skew_q1vec     skew_q2vec  \\\n",
       "count       393325.000000        393325.000000  393325.000000  393325.000000   \n",
       "mean             0.298953             0.367942       0.010352       0.010401   \n",
       "std              0.139067             0.195305       0.135298       0.134904   \n",
       "min              0.000000             0.000000      -0.669451      -0.669451   \n",
       "25%              0.215150             0.245304      -0.080458      -0.080101   \n",
       "50%              0.299724             0.351586       0.011966       0.011953   \n",
       "75%              0.385468             0.471933       0.101535       0.100640   \n",
       "max              0.682163             1.101037       0.675833       0.781670   \n",
       "\n",
       "           kur_q1vec      kur_q2vec  \n",
       "count  393325.000000  393325.000000  \n",
       "mean       -0.052685      -0.054127  \n",
       "std         0.265730       0.264215  \n",
       "min        -0.857844      -0.829341  \n",
       "25%        -0.238232      -0.239380  \n",
       "50%        -0.081463      -0.082807  \n",
       "75%         0.101924       0.100228  \n",
       "max         2.288984       2.227666  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_features.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_data[0::,3::])\n",
    "\n",
    "y_train = train_data[0::, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19076723 -0.11574718  0.29341364 ..., -0.75833929  0.38799228\n",
      "   1.48147671]\n",
      " [-0.31230969  0.80070182 -1.11204323 ...,  0.62491078  1.26705555\n",
      "   0.07449748]\n",
      " [ 0.42553645 -0.05662144  0.4461807  ...,  0.99443795  0.29896417\n",
      "  -1.58963206]\n",
      " ..., \n",
      " [-1.45261735 -1.29826201  0.01843295 ..., -1.16928459 -0.85365441\n",
      "  -1.30004414]\n",
      " [ 1.12984413  1.95365378 -0.98982959 ..., -1.22979346 -1.24111792\n",
      "  -0.41197355]\n",
      " [-0.78184814 -0.47050163 -0.22599433 ...,  1.31754859  2.03282159\n",
      "   2.04993959]]\n",
      "{0, 1}\n",
      "(393325, 28)\n",
      "(393325,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(set(y_train))\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def clf_eval(clf, X, y_true, classes=['Não Repetidas', 'Repetidas']):\n",
    "    y_pred = clf.predict(X)\n",
    "    y_pred = np.asarray(y_pred, dtype=np.int)\n",
    "    y_true = np.asarray(y_true, dtype=np.int)\n",
    "    for i in range(len(y_pred)):\n",
    "        if type(y_pred[i]) != type(y_true[i]):\n",
    "            print(type(y_pred[i]), type(y_true[i]))\n",
    "            break\n",
    "    clf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_true, y_pred, target_names=classes))\n",
    "    print('ROC Score: {}'.format(roc_auc_score(y_true, y_pred)))\n",
    "    print('Accuracy Score: {}'.format(accuracy_score(y_true, y_pred)))\n",
    "    print('Average Precision Score: {}'.format(average_precision_score(y_true, y_pred)))\n",
    "    print('f1 Score: {}'.format(f1_score(y_true, y_pred)))\n",
    "    plot_confusion_matrix(clf_matrix, classes=classes)\n",
    "    return roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Primeira tentativa\n",
    "\n",
    "Cross Validation e XGBoost \n",
    "\n",
    "Sem tuning dos parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275327 117998 275327 117998\n"
     ]
    }
   ],
   "source": [
    "X_traincv, X_testcv, y_traincv, y_testcv = model_selection.train_test_split(X_train,\n",
    "                                                                            y_train,\n",
    "                                                                            test_size=0.3,\n",
    "                                                                            random_state=0)\n",
    "print(len(X_traincv), len(X_testcv), len(y_traincv), len(y_testcv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_traincv = np.asarray(y_traincv, dtype=\"|S6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117998\n",
      "117998\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "clf_xgb1 = xgboost.sklearn.XGBClassifier(base_score=0.5,\n",
    "                                        learning_rate=0.1,\n",
    "                                        n_estimators=250,\n",
    "                                        max_delta_step=0,\n",
    "                                        max_depth=3,\n",
    "                                        min_child_weight=1,\n",
    "                                        missing=None,\n",
    "                                        gamma=0,\n",
    "                                        subsample=1,\n",
    "                                        colsample_bylevel=1,\n",
    "                                        colsample_bytree=1,\n",
    "                                        objective= 'binary:logitraw',\n",
    "                                        #objective='multi:softprob',\n",
    "                                        reg_alpha=0, \n",
    "                                        reg_lambda=1,\n",
    "                                        nthread=-1,\n",
    "                                        scale_pos_weight=1,\n",
    "                                        seed=0,\n",
    "                                        silent=False,).fit(X_traincv, y_traincv)\n",
    "print(len(clf_xgb.predict(X_testcv)))\n",
    "print(len(y_testcv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Não Repetidas       0.70      0.93      0.80     74095\n",
      "    Repetidas       0.72      0.32      0.44     43903\n",
      "\n",
      "  avg / total       0.71      0.70      0.66    117998\n",
      "\n",
      "ROC Score: 0.6224522738989107\n",
      "Accuracy Score: 0.7002830556450109\n",
      "Average Precision Score: 0.6459209678723716\n",
      "f1 Score: 0.44140131412686373\n",
      "Confusion matrix, without normalization\n",
      "[[68659  5436]\n",
      " [29930 13973]]\n"
     ]
    }
   ],
   "source": [
    "roc_xgb = clf_eval(clf_xgb1, X_testcv, y_testcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
